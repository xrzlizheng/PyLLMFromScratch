{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86948bbd",
   "metadata": {},
   "source": [
    "# Mem0 实现：LLM 代理的可扩展长期记忆（精修版）\n",
    "\n",
    "本笔记本提供了 Mem0 架构的详细演练和简化实现，重点关注其核心机制，并与全上下文方法进行令牌效率比较。此版本旨在运行期间输出更简洁，将详细日志存储在变量中供后续检查，并以结构化 DataFrame 呈现最终的令牌比较结果。\n",
    "\n",
    "**场景**：AI 助手帮助用户规划\"新营销活动\"。\n",
    "\n",
    "**实现的核心 Mem0 概念（简化版）**：\n",
    "1. 记忆提取（`ϕ`）\n",
    "2. 记忆存储（带嵌入的文本事实）\n",
    "3. 记忆更新逻辑（通过 LLM 实现 ADD、UPDATE、NOOP）\n",
    "4. 记忆检索（针对查询上下文的语义搜索）\n",
    "\n",
    "**本版本改进**：\n",
    "- 减少默认控制台输出\n",
    "- 通过 `VERBOSE_RAW_RUN` 和 `VERBOSE_MEM0_RUN` 标志按需启用详细日志记录\n",
    "- 将逐轮详细日志存储在 `raw_run_log` 和 `mem0_run_log` 变量中\n",
    "- 最终令牌比较结果以 Pandas DataFrame 呈现\n",
    "\n",
    "## 1. 设置：库、API 配置和辅助函数\n",
    "\n",
    "### 1.1. 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保安装以下必要包：\n",
    "# !pip install openai scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f159773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入标准库和第三方库，用于内存、LLM 和数据处理\n",
    "import os      # 操作系统交互\n",
    "import json    # JSON 解析/生成（LLM 输出）\n",
    "import time    # API 调用间的延迟\n",
    "import uuid    # 唯一内存项 ID\n",
    "from datetime import datetime  # 时间戳\n",
    "\n",
    "import numpy as np            # 嵌入向量\n",
    "import pandas as pd           # DataFrame/表格分析\n",
    "from openai import OpenAI     # OpenAI 兼容的 LLM/嵌入 API\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # 嵌入相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af890fb",
   "metadata": {},
   "source": [
    "### 1.2. API 和模型配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e590c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- API 和模型配置 ---\n",
    "\n",
    "# 从环境变量获取 API 密钥（已在变量 API_KEY 中设置）\n",
    "# 如果未设置，则抛出错误以防止未经认证的请求\n",
    "API_KEY = os.getenv(\"NEBIUS_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"API 密钥未设置。请设置 NEBIUS_API_KEY 环境变量。\")\n",
    "\n",
    "# 设置 Nebius API 的基础 URL\n",
    "BASE_URL = \"https://api.studio.nebius.com/v1/\"\n",
    "\n",
    "# 指定用于生成响应、提取事实和做出更新决策的 LLM 模型\n",
    "# 建议使用更强大的模型以获得更好的 Mem0 性能\n",
    "LLM_MODEL = \"deepseek-ai/DeepSeek-V3\"\n",
    "\n",
    "# 指定用于生成文本嵌入的嵌入模型\n",
    "EMBEDDING_MODEL = \"BAAI/bge-multilingual-gemma2\"\n",
    "\n",
    "# 使用指定的基础 URL 和 API 密钥初始化 OpenAI 兼容客户端\n",
    "client = OpenAI(\n",
    "    base_url=BASE_URL,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "print(f\"OpenAI 客户端已配置。使用 LLM: {LLM_MODEL}, 嵌入: {EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcabb99a",
   "metadata": {},
   "source": [
    "### 1.3. 全局令牌计数器和日志变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 全局令牌计数器 ---\n",
    "# 跟踪两种方法和每个 Mem0 子任务的令牌使用情况\n",
    "total_prompt_tokens_raw, total_completion_tokens_raw = 0, 0  # 原始/全上下文方法\n",
    "total_prompt_tokens_mem0_conversation, total_completion_tokens_mem0_conversation = 0, 0  # Mem0: 对话查询\n",
    "total_prompt_tokens_mem0_extraction, total_completion_tokens_mem0_extraction = 0, 0      # Mem0: 提取子任务\n",
    "total_prompt_tokens_mem0_update, total_completion_tokens_mem0_update = 0, 0              # Mem0: 更新子任务\n",
    "\n",
    "# --- 日志变量 ---\n",
    "# 存储每次运行的详细日志供后续检查或分析\n",
    "raw_run_log = []   # 原始/全上下文方法的日志\n",
    "mem0_run_log = []  # Mem0 方法的日志\n",
    "\n",
    "def reset_all_token_counters_and_logs():\n",
    "    \"\"\"\n",
    "    重置所有全局令牌计数器和日志列表为零/空。\n",
    "    确保在运行新实验或比较前有干净的起点。\n",
    "    \"\"\"\n",
    "    global total_prompt_tokens_raw, total_completion_tokens_raw, \\\n",
    "              total_prompt_tokens_mem0_conversation, total_completion_tokens_mem0_conversation, \\\n",
    "              total_prompt_tokens_mem0_extraction, total_completion_tokens_mem0_extraction, \\\n",
    "              total_prompt_tokens_mem0_update, total_completion_tokens_mem0_update, \\\n",
    "              raw_run_log, mem0_run_log\n",
    "\n",
    "    # 将所有令牌计数器重置为零\n",
    "    total_prompt_tokens_raw, total_completion_tokens_raw = 0, 0\n",
    "    total_prompt_tokens_mem0_conversation, total_completion_tokens_mem0_conversation = 0, 0\n",
    "    total_prompt_tokens_mem0_extraction, total_completion_tokens_mem0_extraction = 0, 0\n",
    "    total_prompt_tokens_mem0_update, total_completion_tokens_mem0_update = 0, 0\n",
    "\n",
    "    # 清除所有运行日志\n",
    "    raw_run_log = []\n",
    "    mem0_run_log = []\n",
    "    print(\"[计数器和日志] 所有令牌计数器和运行日志已重置。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b52e8f",
   "metadata": {},
   "source": [
    "### 1.4. 核心 LLM 和嵌入辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf06215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text_to_embed, verbose=False):\n",
    "    \"\"\"\n",
    "    使用配置的嵌入模型为给定文本生成嵌入向量。\n",
    "    参数：\n",
    "        text_to_embed (str): 要嵌入的输入文本\n",
    "        verbose (bool): 如果为 True，打印错误消息\n",
    "    返回：\n",
    "        np.ndarray: 作为 numpy 数组的嵌入向量。失败时返回零向量。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 调用嵌入 API 获取嵌入向量\n",
    "        response = client.embeddings.create(model=EMBEDDING_MODEL, input=text_to_embed)\n",
    "        return np.array(response.data[0].embedding)\n",
    "    except Exception as e:\n",
    "        # 失败时打印错误（如果 verbose）并返回预期维度的零向量\n",
    "        if verbose: print(f\"[错误] 嵌入失败 '{text_to_embed[:50]}...': {e}。返回零向量。\")\n",
    "        default_embedding_dim = 2560  # 如果模型维度不同，请调整\n",
    "        return np.zeros(default_embedding_dim)\n",
    "\n",
    "def get_llm_chat_completion(messages, temperature=0.1, max_tokens=150, verbose=False):\n",
    "    \"\"\"\n",
    "    使用给定的消息和参数调用 LLM 聊天补全 API。\n",
    "    参数：\n",
    "        messages (list): 聊天历史的消息字典列表\n",
    "        temperature (float): LLM 的采样温度\n",
    "        max_tokens (int): 补全中生成的最大令牌数\n",
    "        verbose (bool): 如果为 True，打印错误消息\n",
    "    返回：\n",
    "        tuple: (response_content, prompt_tokens, completion_tokens)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 调用 LLM 聊天补全 API\n",
    "        response = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        prompt_tokens = response.usage.prompt_tokens if response.usage else 0\n",
    "        completion_tokens = response.usage.completion_tokens if response.usage else 0\n",
    "        return content, prompt_tokens, completion_tokens\n",
    "    except Exception as e:\n",
    "        # 失败时打印错误（如果 verbose）并返回错误消息和零令牌\n",
    "        if verbose: print(f\"[错误] LLM 聊天补全失败: {e}。返回错误消息。\")\n",
    "        return f\"错误: LLM 调用失败。{e}\", 0, 0\n",
    "\n",
    "print(\"嵌入和 LLM 调用的辅助函数已定义。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafc932",
   "metadata": {},
   "source": [
    "## 2. 对话场景：规划营销活动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ca5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将会话脚本定义为用户轮次的列表（每个轮次是一个字典）\n",
    "conversation_script = [\n",
    "    # 用户陈述活动的主要目标\n",
    "    {\"role\": \"user\", \"content\": \"Hi, let's start planning the 'New Marketing Campaign'. My primary goal is to increase brand awareness by 20%.\"},\n",
    "    # 用户指定目标受众\n",
    "    {\"role\": \"user\", \"content\": \"For this campaign, the target audience is young adults aged 18-25.\"},\n",
    "    # 用户为社交媒体广告分配初始预算\n",
    "    {\"role\": \"user\", \"content\": \"I want to allocate a budget of $5000 for social media ads for the New Marketing Campaign.\"},\n",
    "    # 用户询问活动的主要目标\n",
    "    {\"role\": \"user\", \"content\": \"What's the main goal for the New Marketing Campaign?\"},\n",
    "    # 用户询问目标受众\n",
    "    {\"role\": \"user\", \"content\": \"Who are we targeting for this campaign?\"},\n",
    "    # 用户添加与影响者研究相关的新任务\n",
    "    {\"role\": \"user\", \"content\": \"Let's also consider influencers. Add a task: 'Research potential influencers for the 18-25 demographic' for the New Marketing Campaign.\"},\n",
    "    # 用户更新社交媒体广告的预算\n",
    "    {\"role\": \"user\", \"content\": \"Actually, let's increase the social media ad budget for the New Marketing Campaign to $7500.\"},\n",
    "    # 用户询问当前社交媒体广告的预算\n",
    "    {\"role\": \"user\", \"content\": \"What's the current budget for social media ads for the New Marketing Campaign?\"},\n",
    "    # 用户询问活动的待处理任务\n",
    "    {\"role\": \"user\", \"content\": \"What tasks do I have pending for this campaign?\"},\n",
    "    # 用户表达对视觉内容的偏好\n",
    "    {\"role\": \"user\", \"content\": \"Also, for the New Marketing Campaign, I prefer visual content for this demographic, like short videos and infographics.\"}\n",
    "]\n",
    "\n",
    "print(f\"对话场景已定义，共 {len(conversation_script)} 轮。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_input(user_input):\n",
    "    \"\"\"\n",
    "    使用 LLM 将用户输入分类为查询或陈述。\n",
    "    \n",
    "    参数：\n",
    "        user_input (str): 用户的输入消息\n",
    "    \n",
    "    返回：\n",
    "        str: 如果输入是问题则为\"query\"，否则为\"statement\"\n",
    "    \"\"\"\n",
    "    # 定义系统提示以指导 LLM 分类规则\n",
    "    system_prompt = (\n",
    "        \"You are a classifier. \"\n",
    "        \"A 'query' is a question or request for information. \"\n",
    "        \"A 'statement' is a declaration, instruction, or information that is not a question. \"\n",
    "        \"Respond with only one word: either 'query' or 'statement'.\"\n",
    "    )\n",
    "    # 调用 LLM 对输入进行分类\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"microsoft/phi-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Classify the following input as a query or statement: {user_input}\"}\n",
    "        ]\n",
    "    )\n",
    "    # 提取并规范化分类结果\n",
    "    classification = response.choices[0].message.content.strip().lower()\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历会话脚本中的每个轮次\n",
    "for turn in conversation_script:\n",
    "    # 使用 LLM 将用户的输入分类为'query'或'statement'\n",
    "    classification = classify_input(turn[\"content\"])\n",
    "    # 将分类结果添加到轮次字典中的'type'键下\n",
    "    turn[\"type\"] = classification\n",
    "    # 打印输入及其分类以进行验证\n",
    "    print(f\"Input: {turn['content']}, Classification: {classification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81443ea6",
   "metadata": {},
   "source": [
    "## 3. 方法 1：原始/全上下文方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40003d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE_RAW_RUN = False  # 设置为 True 以获取详细的逐轮控制台输出\n",
    "\n",
    "def run_raw_full_context_approach(script):\n",
    "    \"\"\"\n",
    "    使用原始/全上下文方法运行对话：\n",
    "    - 每个用户轮次都附加到完整的对话历史中\n",
    "    - LLM 接收整个对话历史以生成每个响应\n",
    "    - 记录令牌使用情况和响应以供分析\n",
    "    \"\"\"\n",
    "    global total_prompt_tokens_raw, total_completion_tokens_raw, raw_run_log\n",
    "\n",
    "    print(\"--- 运行原始/全上下文方法 ---\")\n",
    "    # 使用系统提示初始化对话历史\n",
    "    current_conversation_history_for_llm = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Respond based on the full conversation history.\"}\n",
    "    ]\n",
    "\n",
    "    for i, turn_details in enumerate(script):\n",
    "        user_message_content = turn_details['content']\n",
    "        turn_type = turn_details['type']\n",
    "\n",
    "        if VERBOSE_RAW_RUN:\n",
    "            print(f\"\\n--- 原始轮次 {i+1}/{len(script)} (类型: {turn_type}) ---\")\n",
    "        print(f\"原始轮次 {i+1} 用户: {user_message_content[:80]}...\")\n",
    "\n",
    "        # 将用户消息添加到对话历史\n",
    "        current_conversation_history_for_llm.append({\"role\": \"user\", \"content\": user_message_content})\n",
    "\n",
    "        # 使用完整对话历史调用 LLM\n",
    "        assistant_response_text, p_tokens, c_tokens = get_llm_chat_completion(\n",
    "            current_conversation_history_for_llm, max_tokens=150, verbose=VERBOSE_RAW_RUN\n",
    "        )\n",
    "\n",
    "        # 更新全局令牌计数器\n",
    "        total_prompt_tokens_raw += p_tokens\n",
    "        total_completion_tokens_raw += c_tokens\n",
    "\n",
    "        print(f\"原始轮次 {i+1} 助手: {assistant_response_text[:80]}...\")\n",
    "        if VERBOSE_RAW_RUN:\n",
    "            print(f\"此轮次令牌 (Prompt: {p_tokens}, Completion: {c_tokens})\")\n",
    "            print(f\"累计原始令牌 (Prompt: {total_prompt_tokens_raw}, Completion: {total_completion_tokens_raw})\")\n",
    "\n",
    "        # 将助手响应添加到对话历史\n",
    "        current_conversation_history_for_llm.append({\"role\": \"assistant\", \"content\": assistant_response_text})\n",
    "\n",
    "        # 记录轮次详情供后续分析\n",
    "        raw_run_log.append({\n",
    "            \"turn\": i + 1,\n",
    "            \"type\": turn_type,\n",
    "            \"user_content\": user_message_content,\n",
    "            \"assistant_response\": assistant_response_text,\n",
    "            \"prompt_tokens_turn\": p_tokens,\n",
    "            \"completion_tokens_turn\": c_tokens,\n",
    "            \"cumulative_prompt_tokens\": total_prompt_tokens_raw,\n",
    "            \"cumulative_completion_tokens\": total_completion_tokens_raw\n",
    "        })\n",
    "\n",
    "        time.sleep(0.2)  # 减少睡眠时间，如果速率限制有问题请调整\n",
    "\n",
    "    print(\"\\n--- 原始/全上下文方法摘要 ---\")\n",
    "    print(f\"总提示令牌: {total_prompt_tokens_raw}\")\n",
    "    print(f\"总补全令牌: {total_completion_tokens_raw}\")\n",
    "    print(f\"原始方法总令牌数: {total_prompt_tokens_raw + total_completion_tokens_raw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285de71",
   "metadata": {},
   "source": [
    "## 4. 方法 2：Mem0 实现\n",
    "\n",
    "### 4.1. 记忆项和记忆存储类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryItem:\n",
    "    def __init__(self, text_content, source_turn_indices_list, verbose_embedding=False):\n",
    "        \"\"\"\n",
    "        表示具有文本、嵌入和元数据的单个记忆项。\n",
    "        \n",
    "        参数：\n",
    "            text_content (str): 要存储在记忆中的内容\n",
    "            source_turn_indices_list (list): 贡献于此记忆的对话轮次索引列表\n",
    "            verbose_embedding (bool): 如果为 True，打印嵌入错误\n",
    "        \"\"\"\n",
    "        self.id = str(uuid.uuid4())  # 记忆项的唯一标识符\n",
    "        self.text = text_content  # 实际记忆内容\n",
    "        self.embedding = get_embedding(text_content, verbose=verbose_embedding)  # 嵌入向量\n",
    "        self.creation_timestamp = datetime.now()  # 记忆创建时间\n",
    "        self.last_accessed_timestamp = self.creation_timestamp  # 最后访问时间\n",
    "        self.access_count = 0  # 访问次数\n",
    "        self.source_turn_indices = list(source_turn_indices_list)  # 来源轮次用于溯源\n",
    "\n",
    "    def __repr__(self):\n",
    "        # 用于调试的字符串表示\n",
    "        return (f\"MemoryItem(id={self.id}, text='{self.text[:60]}...', \"\n",
    "                f\"created={self.creation_timestamp.strftime('%H:%M:%S')}, accessed={self.access_count})\")\n",
    "\n",
    "    def mark_accessed(self):\n",
    "        # 当记忆被访问时更新访问元数据\n",
    "        self.last_accessed_timestamp = datetime.now()\n",
    "        self.access_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50459f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryStore:\n",
    "    def __init__(self, verbose_ops=False):\n",
    "        \"\"\"\n",
    "        存储和管理多个 MemoryItem 实例。\n",
    "        \n",
    "        参数：\n",
    "            verbose_ops (bool): 如果为 True，打印操作的调试信息\n",
    "        \"\"\"\n",
    "        self.memories = {}  # 存储 memory_id -> MemoryItem 的字典\n",
    "        self.verbose = verbose_ops\n",
    "        if self.verbose:\n",
    "            print(\"[MemoryStore] 初始化了一个空的记忆存储。\")\n",
    "\n",
    "    def add_memory_item(self, memory_item_instance):\n",
    "        \"\"\"\n",
    "        向存储中添加新的 MemoryItem。\n",
    "        \n",
    "        参数：\n",
    "            memory_item_instance (MemoryItem): 要添加的记忆项\n",
    "        \"\"\"\n",
    "        self.memories[memory_item_instance.id] = memory_item_instance\n",
    "        if self.verbose:\n",
    "            print(f\"[MemoryStore] 已添加: '{memory_item_instance.text[:70]}' (ID: {memory_item_instance.id})\")\n",
    "\n",
    "    def get_memory_item_by_id(self, memory_id):\n",
    "        \"\"\"\n",
    "        通过 ID 检索 MemoryItem 并标记为已访问。\n",
    "        \n",
    "        参数：\n",
    "            memory_id (str): 记忆项的 ID\n",
    "        \n",
    "        返回：\n",
    "            MemoryItem 或 None: 如果找到则返回记忆项，否则返回 None\n",
    "        \"\"\"\n",
    "        if memory_id in self.memories:\n",
    "            self.memories[memory_id].mark_accessed()  # 标记为已访问\n",
    "            return self.memories[memory_id]\n",
    "        return None\n",
    "\n",
    "    def update_existing_memory_item(self, memory_id, new_text_content, contributing_turn_indices):\n",
    "        \"\"\"\n",
    "        更新现有记忆项的文本和嵌入。\n",
    "        \n",
    "        参数：\n",
    "            memory_id (str): 要更新的记忆 ID\n",
    "            new_text_content (str): 新的文本内容\n",
    "            contributing_turn_indices (list): 要添加的额外轮次索引\n",
    "        \n",
    "        返回：\n",
    "            bool: 如果更新成功则为 True，否则为 False\n",
    "        \"\"\"\n",
    "        if memory_id in self.memories:\n",
    "            memory_to_update = self.memories[memory_id]\n",
    "            original_text_preview = memory_to_update.text[:70]\n",
    "            # 更新文本和嵌入\n",
    "            memory_to_update.text = new_text_content\n",
    "            memory_to_update.embedding = get_embedding(new_text_content, verbose=self.verbose)\n",
    "            memory_to_update.creation_timestamp = datetime.now()\n",
    "            # 添加新的贡献轮次索引（如果尚未存在）\n",
    "            for turn_idx in contributing_turn_indices:\n",
    "                if turn_idx not in memory_to_update.source_turn_indices:\n",
    "                    memory_to_update.source_turn_indices.append(turn_idx)\n",
    "            memory_to_update.mark_accessed()\n",
    "            if self.verbose:\n",
    "                print(f\"[MemoryStore] 已更新 ID {memory_id}: 从 '{original_text_preview}' 到 '{new_text_content[:70]}'\")\n",
    "            return True\n",
    "        if self.verbose:\n",
    "            print(f\"[MemoryStore] 更新失败: ID {memory_id} 未找到。\")\n",
    "        return False\n",
    "\n",
    "    def find_semantically_similar_memories(self, query_text_embedding, top_s_results=3, similarity_threshold=0.5):\n",
    "        \"\"\"\n",
    "        找到与查询嵌入最相似的记忆。\n",
    "        \n",
    "        参数：\n",
    "            query_text_embedding (np.ndarray): 查询文本的嵌入\n",
    "            top_s_results (int): 返回的最大结果数\n",
    "            similarity_threshold (float): 考虑的最小相似度分数\n",
    "        \n",
    "        返回：\n",
    "            list: (MemoryItem, similarity_score) 元组的列表\n",
    "        \"\"\"\n",
    "        # 如果没有记忆或查询嵌入无效，则返回空\n",
    "        if not self.memories or query_text_embedding is None or query_text_embedding.size == 0:\n",
    "            return []\n",
    "        # 过滤掉嵌入无效的记忆\n",
    "        valid_memories_for_similarity = [\n",
    "            (mid, self.memories[mid].embedding) for mid in self.memories\n",
    "            if self.memories[mid].embedding is not None and \n",
    "               self.memories[mid].embedding.size > 0 and \n",
    "               np.any(self.memories[mid].embedding)  # 确保不全为零\n",
    "        ]\n",
    "        if not valid_memories_for_similarity:\n",
    "            return []\n",
    "        valid_memory_ids = [item[0] for item in valid_memories_for_similarity]\n",
    "        valid_memory_embeddings = np.array([item[1] for item in valid_memories_for_similarity])\n",
    "        # 处理单个有效记忆的情况\n",
    "        if valid_memory_embeddings.ndim == 1:\n",
    "            valid_memory_embeddings = valid_memory_embeddings.reshape(1, -1)\n",
    "        if query_text_embedding.ndim == 1:\n",
    "            query_text_embedding = query_text_embedding.reshape(1, -1)\n",
    "\n",
    "        # 计算查询与所有有效记忆之间的余弦相似度\n",
    "        similarities_vector = cosine_similarity(query_text_embedding, valid_memory_embeddings)[0]\n",
    "        sorted_similarity_indices = np.argsort(similarities_vector)[::-1]\n",
    "        retrieved_similar_memories = []\n",
    "        # 收集高于阈值的顶部结果\n",
    "        for i in range(min(top_s_results, len(sorted_similarity_indices))):\n",
    "            idx = sorted_similarity_indices[i]\n",
    "            similarity_score = similarities_vector[idx]\n",
    "            if similarity_score >= similarity_threshold:\n",
    "                retrieved_similar_memories.append((self.memories[valid_memory_ids[idx]], similarity_score))\n",
    "            else:\n",
    "                break\n",
    "        return retrieved_similar_memories\n",
    "\n",
    "    def clear_store(self):\n",
    "        \"\"\"\n",
    "        清除存储中的所有记忆。\n",
    "        \"\"\"\n",
    "        self.memories = {}\n",
    "        if self.verbose:\n",
    "            print(\"[MemoryStore] 记忆存储已清除。\")\n",
    "\n",
    "# 实例化记忆存储（设置 verbose_ops=True 以获取调试输出）\n",
    "mem0_memory_store = MemoryStore(verbose_ops=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55884e",
   "metadata": {},
   "source": [
    "### 4.2. 记忆提取函数（`ϕ`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a957c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem0_extract_salient_facts_from_turn(current_user_statement_text, recent_turns_window_text, current_turn_index_in_script, verbose=False):\n",
    "    \"\"\"\n",
    "    使用 LLM 从用户陈述中提取简洁、自包含的陈述性事实，\n",
    "    考虑最近的对话上下文。返回事实字符串列表。\n",
    "    \n",
    "    参数：\n",
    "        current_user_statement_text (str): 用户的当前陈述\n",
    "        recent_turns_window_text (str): 作为文本的最近对话上下文\n",
    "        current_turn_index_in_script (int): 当前轮次在脚本中的索引\n",
    "        verbose (bool): 如果为 True，打印调试信息\n",
    "    \n",
    "    返回：\n",
    "        list: 提取的事实字符串列表\n",
    "    \"\"\"\n",
    "    global total_prompt_tokens_mem0_extraction, total_completion_tokens_mem0_extraction\n",
    "\n",
    "    # 为 LLM 构建提取提示\n",
    "    extraction_prompt_template = f\"\"\"\n",
    "    You are an AI expert in extracting key information from dialogue.\n",
    "    Analyze 'New User Statement' in context of 'Recent Conversation Context'.\n",
    "    Extract concise, self-contained, declarative facts representing new, important user-provided information from 'New User Statement'.\n",
    "    Each fact: complete sentence. Focus: user's goals, plans, preferences, decisions, key entities.\n",
    "    Avoid: questions, acknowledgements, fluff. If statement updates info, extract updated fact. Do NOT infer.\n",
    "    Recent Conversation Context:\n",
    "    ---BEGIN CONTEXT---\n",
    "    {recent_turns_window_text if recent_turns_window_text else \"(No prior context)\"}\n",
    "    ---END CONTEXT---\n",
    "    New User Statement to Process: \"{current_user_statement_text}\"\n",
    "    Output ONLY a valid JSON list of strings (facts). E.g.: [\"Fact 1.\", \"Fact 2.\"]. Empty list [] if no new salient facts.\n",
    "    Extracted Facts (JSON list):\n",
    "    \"\"\"\n",
    "    # 为 LLM 调用准备消息\n",
    "    extraction_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Expert extraction AI. Output ONLY valid JSON list of facts.\"},\n",
    "        {\"role\": \"user\", \"content\": extraction_prompt_template}\n",
    "    ]\n",
    "\n",
    "    # 调用 LLM 提取事实\n",
    "    llm_extraction_response_text, p_tokens, c_tokens = get_llm_chat_completion(\n",
    "        extraction_messages, temperature=0.0, max_tokens=250, verbose=verbose\n",
    "    )\n",
    "\n",
    "    # 更新全局令牌计数器\n",
    "    total_prompt_tokens_mem0_extraction += p_tokens\n",
    "    total_completion_tokens_mem0_extraction += c_tokens\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[Extractor LLM] 原始输出: {llm_extraction_response_text}\")\n",
    "\n",
    "    # 尝试将 LLM 的输出解析为字符串的 JSON 列表\n",
    "    try:\n",
    "        json_start_index = llm_extraction_response_text.find('[')\n",
    "        json_end_index = llm_extraction_response_text.rfind(']')\n",
    "        if json_start_index != -1 and json_end_index != -1 and json_end_index > json_start_index:\n",
    "            json_string_candidate = llm_extraction_response_text[json_start_index : json_end_index+1]\n",
    "            parsed_facts_list = json.loads(json_string_candidate)\n",
    "            if isinstance(parsed_facts_list, list) and all(isinstance(fact, str) for fact in parsed_facts_list):\n",
    "                if verbose or len(parsed_facts_list) > 0:\n",
    "                    print(f\"[Extractor LLM] 解析了 {len(parsed_facts_list)} 个事实。\")\n",
    "                return parsed_facts_list\n",
    "            if verbose:\n",
    "                print(f\"[Extractor LLM] 警告: 解析的 JSON 不是字符串列表: {parsed_facts_list}。返回 []。\")\n",
    "        elif verbose:\n",
    "            print(f\"[Extractor LLM] 警告: 在 '{llm_extraction_response_text}' 中没有有效的 JSON 列表括号。返回 []。\")\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"[Extractor LLM] 解析 JSON 错误: {e}。响应: '{llm_extraction_response_text}'。返回 []。\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83743039",
   "metadata": {},
   "source": [
    "### 4.3. 记忆更新逻辑（ADD、UPDATE、NOOP）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于更新决策的相似记忆数量\n",
    "S_SIMILAR_MEMORIES_FOR_UPDATE_DECISION = 3\n",
    "\n",
    "def mem0_decide_memory_operation_with_llm(candidate_fact_text, similar_existing_memories_list, verbose=False):\n",
    "    \"\"\"\n",
    "    使用 LLM 决定是 ADD、UPDATE 还是 NOOP 候选事实到记忆中，\n",
    "    基于其与现有记忆的相似性。\n",
    "    \n",
    "    参数：\n",
    "        candidate_fact_text (str): 从用户输入中提取的新事实\n",
    "        similar_existing_memories_list (list): (MemoryItem, similarity_score) 元组列表\n",
    "        verbose (bool): 如果为 True，打印调试信息\n",
    "    \n",
    "    返回：\n",
    "        dict: 带有操作决策的 JSON 对象，例如，\n",
    "              {\"operation\": \"ADD\"} 或\n",
    "              {\"operation\": \"UPDATE\", \"target_memory_id\": \"ID\", \"updated_memory_text\": \"Text\"} 或\n",
    "              {\"operation\": \"NOOP\"}\n",
    "    \"\"\"\n",
    "    global total_prompt_tokens_mem0_update, total_completion_tokens_mem0_update\n",
    "\n",
    "    # 准备描述相似记忆的提示段（如果有）\n",
    "    similar_memories_prompt_segment = \"No highly similar memories found.\"\n",
    "    if similar_existing_memories_list:\n",
    "        formatted_list = [\n",
    "            f\"  {i+1}. ID: {mem.id}, Sim: {sim_score:.4f}, Text: '{mem.text}'\"\n",
    "            for i, (mem, sim_score) in enumerate(similar_existing_memories_list)\n",
    "        ]\n",
    "        similar_memories_prompt_segment = \"Existing Similar Memories:\\n\" + \"\\n\".join(formatted_list)\n",
    "    \n",
    "    # 为 LLM 构建更新决策提示\n",
    "    formatted_update_decision_prompt = f\"\"\"\n",
    "    AI Memory Consolidation Module.\n",
    "    Task: Integrate 'New Candidate Fact' into memory store.\n",
    "    New Candidate Fact: \"{candidate_fact_text}\"\n",
    "    {similar_memories_prompt_segment}\n",
    "    Decide ONE operation: ADD, UPDATE, or NOOP.\n",
    "    Rules:\n",
    "    1. ADD: If new info, not covered by similar memories (or no similar found).\n",
    "    2. UPDATE: If fact corrects, makes current, or adds essential detail to ONE similar memory, superseding it. Specify 'target_memory_id' (from list) and 'updated_memory_text' (usually New Candidate Fact text).\n",
    "    3. NOOP: If redundant or no new substantive value over existing similar memories.\n",
    "    Output STRICTLY JSON: {{ \"operation\": \"ADD\" }} OR {{ \"operation\": \"UPDATE\", \"target_memory_id\": \"ID\", \"updated_memory_text\": \"Text\" }} OR {{ \"operation\": \"NOOP\" }}\n",
    "    Decision (JSON object):\n",
    "    \"\"\"\n",
    "    # 为 LLM 调用准备消息\n",
    "    update_decision_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Expert memory AI. Output ONLY valid JSON decision as instructed.\"},\n",
    "        {\"role\": \"user\", \"content\": formatted_update_decision_prompt}\n",
    "    ]\n",
    "\n",
    "    # 调用 LLM 获取更新决策\n",
    "    llm_decision_response_text, p_tokens, c_tokens = get_llm_chat_completion(\n",
    "        update_decision_messages, temperature=0.0, max_tokens=200, verbose=verbose\n",
    "    )\n",
    "\n",
    "    # 更新全局令牌计数器\n",
    "    total_prompt_tokens_mem0_update += p_tokens\n",
    "    total_completion_tokens_mem0_update += c_tokens\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[Updater LLM] 原始输出: {llm_decision_response_text}\")\n",
    "\n",
    "    # 尝试将 LLM 的输出解析为 JSON 对象\n",
    "    try:\n",
    "        json_start_index = llm_decision_response_text.find('{')\n",
    "        json_end_index = llm_decision_response_text.rfind('}')\n",
    "        if json_start_index != -1 and json_end_index != -1 and json_end_index > json_start_index:\n",
    "            json_string_candidate = llm_decision_response_text[json_start_index : json_end_index+1]\n",
    "            parsed_decision_json = json.loads(json_string_candidate)\n",
    "            op = parsed_decision_json.get(\"operation\")\n",
    "            # 检查有效的操作类型和必填字段\n",
    "            if op in [\"ADD\", \"NOOP\"]:\n",
    "                if verbose or op == \"NOOP\":\n",
    "                    print(f\"[Updater LLM] 解析的决策: {op}\")\n",
    "                return parsed_decision_json\n",
    "            elif op == \"UPDATE\" and \"target_memory_id\" in parsed_decision_json and \"updated_memory_text\" in parsed_decision_json:\n",
    "                if verbose:\n",
    "                    print(f\"[Updater LLM] 解析的决策: {op}\")\n",
    "                return parsed_decision_json\n",
    "            if verbose:\n",
    "                print(f\"[Updater LLM] 警告: 无效的决策结构: {parsed_decision_json}。默认为 ADD。\")\n",
    "        elif verbose:\n",
    "            print(f\"[Updater LLM] 警告: 在 '{llm_decision_response_text}' 中没有有效的 JSON 对象括号。默认为 ADD。\")\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"[Updater LLM] 解析 JSON 错误: {e}。响应: '{llm_decision_response_text}'。默认为 ADD。\")\n",
    "    # 默认回退: ADD 操作\n",
    "    return {\"operation\": \"ADD\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f7c3f",
   "metadata": {},
   "source": [
    "### 4.4. 协调记忆提取和更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem0_process_user_statement_for_memory(user_statement_text, recent_turns_context_text, memory_store_instance, current_turn_idx, turn_log_entry, verbose=False):\n",
    "    \"\"\"\n",
    "    协调从用户陈述中提取显著事实的过程，\n",
    "    确定每个事实的记忆操作（ADD、UPDATE、NOOP），并相应地更新记忆存储。\n",
    "    \n",
    "    参数：\n",
    "        user_statement_text (str): 要处理的用户陈述\n",
    "        recent_turns_context_text (str): 用于提取的最近对话上下文\n",
    "        memory_store_instance (MemoryStore): 要更新的记忆存储\n",
    "        current_turn_idx (int): 当前轮次在脚本中的索引\n",
    "        turn_log_entry (dict): 此轮次的日志条目（用于详细日志记录）\n",
    "        verbose (bool): 如果为 True，打印详细的调试信息\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"[MemoryOrchestrator] 处理: '{user_statement_text[:60]}...' (轮次: {current_turn_idx})\")\n",
    "    turn_log_entry['extraction_details'] = []\n",
    "    turn_log_entry['update_details'] = []\n",
    "\n",
    "    # 步骤 1: 使用 LLM 提取器从用户陈述中提取候选事实\n",
    "    candidate_facts_list = mem0_extract_salient_facts_from_turn(\n",
    "        user_statement_text, recent_turns_context_text, current_turn_idx, verbose=verbose\n",
    "    )\n",
    "    turn_log_entry['extracted_facts_raw'] = list(candidate_facts_list)\n",
    "    if not candidate_facts_list:\n",
    "        if verbose:\n",
    "            print(\"[MemoryOrchestrator] 没有提取到候选事实。\")\n",
    "        return\n",
    "    if verbose or len(candidate_facts_list) > 0:\n",
    "        print(f\"[MemoryOrchestrator] 提取了 {len(candidate_facts_list)} 个事实。\")\n",
    "\n",
    "    # 步骤 2: 对于每个提取的事实，确定适当的记忆操作\n",
    "    for fact_idx, individual_fact_text in enumerate(candidate_facts_list):\n",
    "        extraction_detail = {\n",
    "            \"candidate_fact\": individual_fact_text,\n",
    "            \"similar_memories_checked\": [],\n",
    "            \"llm_decision\": None\n",
    "        }\n",
    "        if verbose:\n",
    "            print(f\"\\n[MemoryOrchestrator] -> 处理事实 {fact_idx+1}: '{individual_fact_text[:60]}...'\")\n",
    "        # 为候选事实生成嵌入\n",
    "        candidate_fact_embedding = get_embedding(individual_fact_text, verbose=verbose)\n",
    "        # 在存储中查找相似的记忆\n",
    "        similar_memories_found = memory_store_instance.find_semantically_similar_memories(\n",
    "            candidate_fact_embedding, top_s_results=S_SIMILAR_MEMORIES_FOR_UPDATE_DECISION\n",
    "        )\n",
    "        if similar_memories_found:\n",
    "            if verbose:\n",
    "                print(f\"[MemoryOrchestrator]    找到 {len(similar_memories_found)} 个相似记忆。\")\n",
    "            for mem, sim_score in similar_memories_found:\n",
    "                extraction_detail['similar_memories_checked'].append({\n",
    "                    'id': mem.id,\n",
    "                    'text': mem.text,\n",
    "                    'similarity': sim_score\n",
    "                })\n",
    "                if verbose:\n",
    "                    print(f\"[MemoryOrchestrator]     ID: {mem.id}, 相似度: {sim_score:.2f}, 文本: '{mem.text[:50]}...'\")\n",
    "        elif verbose:\n",
    "            print(\"[MemoryOrchestrator]    没有找到高度相似的记忆。\")\n",
    "\n",
    "        # 步骤 3: 使用 LLM 决定 ADD、UPDATE 或 NOOP 操作\n",
    "        llm_decision_json = mem0_decide_memory_operation_with_llm(\n",
    "            individual_fact_text, similar_memories_found, verbose=verbose\n",
    "        )\n",
    "        operation_to_perform = llm_decision_json.get(\"operation\")\n",
    "        extraction_detail['llm_decision'] = llm_decision_json\n",
    "        print(f\"[MemoryOrchestrator] 事实 '{individual_fact_text[:30]}...': LLM 决策 -> {operation_to_perform}\")\n",
    "        turn_log_entry['update_details'].append(extraction_detail)  # 在执行前记录\n",
    "\n",
    "        # 步骤 4: 执行决定的记忆操作\n",
    "        if operation_to_perform == \"ADD\":\n",
    "            # 向存储添加新记忆项\n",
    "            new_memory_item = MemoryItem(\n",
    "                text_content=individual_fact_text,\n",
    "                source_turn_indices_list=[current_turn_idx],\n",
    "                verbose_embedding=verbose\n",
    "            )\n",
    "            memory_store_instance.add_memory_item(new_memory_item)\n",
    "        elif operation_to_perform == \"UPDATE\":\n",
    "            # 更新现有记忆项\n",
    "            target_memory_id = llm_decision_json.get(\"target_memory_id\")\n",
    "            updated_fact_text = llm_decision_json.get(\"updated_memory_text\")\n",
    "            # 检查目标 ID 是否合理（在相似记忆中）\n",
    "            is_plausible_target = any(mem.id == target_memory_id for mem, _ in similar_memories_found)\n",
    "            if target_memory_id and updated_fact_text and is_plausible_target:\n",
    "                memory_store_instance.update_existing_memory_item(\n",
    "                    target_memory_id, updated_fact_text, [current_turn_idx]\n",
    "                )\n",
    "            elif target_memory_id and updated_fact_text:\n",
    "                # 即使不在相似列表中也要尝试更新；如果失败则回退到添加\n",
    "                if verbose:\n",
    "                    print(f\"[MemoryOrchestrator] 警告: UPDATE target_id '{target_memory_id}' 不在相似列表中。尝试更新。\")\n",
    "                if not memory_store_instance.update_existing_memory_item(\n",
    "                    target_memory_id, updated_fact_text, [current_turn_idx]\n",
    "                ):\n",
    "                    if verbose:\n",
    "                        print(f\"[MemoryOrchestrator] 更新失败。添加为新项。\")\n",
    "                    memory_store_instance.add_memory_item(MemoryItem(individual_fact_text, [current_turn_idx], verbose))\n",
    "            else:\n",
    "                # 格式错误的 UPDATE，回退到添加为新项\n",
    "                if verbose:\n",
    "                    print(f\"[MemoryOrchestrator] 警告: UPDATE 格式错误/不合理。添加为新项。\")\n",
    "                memory_store_instance.add_memory_item(MemoryItem(individual_fact_text, [current_turn_idx], verbose))\n",
    "        elif operation_to_perform == \"NOOP\":\n",
    "            # 对于冗余事实不做任何操作\n",
    "            if verbose:\n",
    "                print(f\"[MemoryOrchestrator]    NOOP 事实: '{individual_fact_text[:70]}...'\")\n",
    "        else:\n",
    "            # 回退: 如果未知操作则视为 ADD\n",
    "            if verbose:\n",
    "                print(f\"[MemoryOrchestrator] 警告: 未知操作 '{operation_to_perform}'。默认为 ADD。\")\n",
    "            memory_store_instance.add_memory_item(MemoryItem(individual_fact_text, [current_turn_idx], verbose))\n",
    "        time.sleep(0.1)  # 小延迟以避免 API 速率限制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1de63b",
   "metadata": {},
   "source": [
    "### 4.5. 记忆检索以回答用户查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3058dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_MEMORIES_TO_RETRIEVE_FOR_QUERY = 3\n",
    "\n",
    "def mem0_retrieve_and_format_memories_for_llm_query(\n",
    "    user_query_text, memory_store_instance, turn_log_entry, \n",
    "    top_k_results=K_MEMORIES_TO_RETRIEVE_FOR_QUERY, verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    检索用户查询的 top-k 语义相关记忆，并将其格式化为 LLM 输入。\n",
    "    \n",
    "    参数：\n",
    "        user_query_text (str): 用户的查询\n",
    "        memory_store_instance (MemoryStore): 要搜索的记忆存储\n",
    "        turn_log_entry (dict): 此轮次的日志条目（用于详细日志记录）\n",
    "        top_k_results (int): 要检索的顶部相关记忆数量\n",
    "        verbose (bool): 如果为 True，打印调试信息\n",
    "    \n",
    "    返回：\n",
    "        str: 相关记忆的格式化字符串供 LLM 使用，如果没有找到则返回消息\n",
    "    \"\"\"\n",
    "    # 初始化检索到的记忆日志\n",
    "    turn_log_entry['retrieved_memories_for_query'] = []\n",
    "\n",
    "    # 如果查询为空或记忆存储为空，则提前返回\n",
    "    if not user_query_text.strip() or not memory_store_instance.memories:\n",
    "        return \"(No relevant memories in store or query empty.)\"\n",
    "        \n",
    "    # 为用户查询生成嵌入\n",
    "    query_embedding = get_embedding(user_query_text, verbose=verbose)\n",
    "\n",
    "    # 检索 top-k 语义相似的记忆\n",
    "    retrieved_memories_with_scores = memory_store_instance.find_semantically_similar_memories(\n",
    "        query_embedding, top_s_results=top_k_results\n",
    "    )\n",
    "\n",
    "    # 如果没有找到相关记忆，则返回消息\n",
    "    if not retrieved_memories_with_scores:\n",
    "        return \"(No relevant memories found for this query.)\"\n",
    "    \n",
    "    # 为 LLM 输入格式化检索到的记忆\n",
    "    formatted_memories_string = \"Based on my memory, here's relevant information:\\n\"\n",
    "    for i, (mem_item, similarity_score) in enumerate(retrieved_memories_with_scores):\n",
    "        memory_store_instance.get_memory_item_by_id(mem_item.id)  # 标记为已访问\n",
    "        formatted_memories_string += f\"  {i+1}. {mem_item.text} (Similarity: {similarity_score:.3f})\\n\"\n",
    "        # 记录检索到的记忆详情\n",
    "        turn_log_entry['retrieved_memories_for_query'].append({\n",
    "            'id': mem_item.id, \n",
    "            'text': mem_item.text, \n",
    "            'similarity': similarity_score\n",
    "        })\n",
    "    if verbose:\n",
    "        print(f\"[Retriever] 为 LLM 格式化的记忆: \\n{formatted_memories_string}\")\n",
    "    return formatted_memories_string.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e98de3",
   "metadata": {},
   "source": [
    "### 4.6. 主函数：运行 Mem0 驱动的对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80550dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 控制 Mem0 运行的详细程度（设置为 True 获取详细输出）\n",
    "VERBOSE_MEM0_RUN = False\n",
    "\n",
    "# 用于记忆提取上下文的最近轮次数\n",
    "M_RECENT_RAW_TURNS_FOR_EXTRACTION_CONTEXT = 3\n",
    "\n",
    "# 为 LLM 上下文保留的短期聊天历史中的最近轮次数\n",
    "SHORT_TERM_CHAT_HISTORY_WINDOW = 2\n",
    "\n",
    "def run_mem0_approach_conversation(script, memory_store_instance):\n",
    "    \"\"\"\n",
    "    使用 Mem0 记忆驱动的方法运行对话。\n",
    "    处理用户陈述（用于记忆提取/更新）和查询（用于记忆检索/回答）。\n",
    "    跟踪令牌使用情况并记录每轮的详细信息。\n",
    "    \n",
    "    参数：\n",
    "        script (list): 字典列表，每个字典表示带有 'content' 和 'type' 的用户轮次\n",
    "        memory_store_instance (MemoryStore): 用于此次运行的记忆存储\n",
    "    \"\"\"\n",
    "    global total_prompt_tokens_mem0_conversation, total_completion_tokens_mem0_conversation, mem0_run_log\n",
    "\n",
    "    # 重置记忆存储并设置详细程度\n",
    "    memory_store_instance.clear_store()\n",
    "    memory_store_instance.verbose = VERBOSE_MEM0_RUN\n",
    "\n",
    "    print(\"--- 运行 Mem0 驱动的对话方法 ---\")\n",
    "\n",
    "    # 用于提取上下文的原始日志（用于事实提取）\n",
    "    raw_conversation_log_for_extraction_context = []\n",
    "\n",
    "    # 用于 LLM 上下文的短期聊天历史（系统提示 + 最后 N 轮）\n",
    "    current_short_term_llm_chat_history = [\n",
    "        {\"role\": \"system\", \"content\": \"Helpful AI assistant. Use general knowledge and 'Relevant Information from Memory' to answer concisely.\"}\n",
    "    ]\n",
    "\n",
    "    for turn_index, turn_data in enumerate(script):\n",
    "        user_message_content = turn_data['content']\n",
    "        turn_type = turn_data['type']\n",
    "        turn_log_entry = {\n",
    "            \"turn\": turn_index + 1,\n",
    "            \"type\": turn_type,\n",
    "            \"user_content\": user_message_content\n",
    "        }\n",
    "\n",
    "        print(f\"\\n--- Mem0 轮次 {turn_index + 1}/{len(script)} ({turn_type}) ---\")\n",
    "        print(f\"用户: {user_message_content[:80]}...\")\n",
    "\n",
    "        assistant_response_text = \"(Ack/Internal Processing)\"\n",
    "\n",
    "        # 处理用户陈述（添加/更新记忆）\n",
    "        if turn_type == 'statement' or turn_type == 'statement_update':\n",
    "            # 获取用于提取上下文的最近轮次\n",
    "            start_idx = max(0, len(raw_conversation_log_for_extraction_context) - M_RECENT_RAW_TURNS_FOR_EXTRACTION_CONTEXT)\n",
    "            recent_turns_text = \"\\n\".join(raw_conversation_log_for_extraction_context[start_idx:])\n",
    "\n",
    "            # 提取事实并更新记忆存储\n",
    "            mem0_process_user_statement_for_memory(\n",
    "                user_message_content,\n",
    "                recent_turns_text,\n",
    "                memory_store_instance,\n",
    "                turn_index,\n",
    "                turn_log_entry,\n",
    "                verbose=VERBOSE_MEM0_RUN\n",
    "            )\n",
    "\n",
    "            # 提供确认响应\n",
    "            assistant_response_text = \"Okay, noted.\" if turn_type == 'statement' else \"Okay, updated.\"\n",
    "            print(f\"助手 (确认): {assistant_response_text}\")\n",
    "\n",
    "            # 记录响应和令牌使用情况（确认无需 LLM 调用）\n",
    "            turn_log_entry['assistant_response_conversational'] = assistant_response_text\n",
    "            turn_log_entry['prompt_tokens_conversational_turn'] = 0\n",
    "            turn_log_entry['completion_tokens_conversational_turn'] = 0\n",
    "\n",
    "        # 处理用户查询（检索记忆并回答）\n",
    "        elif turn_type == 'query':\n",
    "            if VERBOSE_MEM0_RUN:\n",
    "                print(f\"[Mem0 Run] 处理查询: '{user_message_content}'\")\n",
    "\n",
    "            # 为查询检索相关记忆\n",
    "            retrieved_memories_text = mem0_retrieve_and_format_memories_for_llm_query(\n",
    "                user_message_content,\n",
    "                memory_store_instance,\n",
    "                turn_log_entry,\n",
    "                verbose=VERBOSE_MEM0_RUN\n",
    "            )\n",
    "\n",
    "            # 准备 LLM 输入: 短期聊天 + 用户查询 + 相关记忆\n",
    "            messages_for_llm = list(current_short_term_llm_chat_history)\n",
    "            messages_for_llm.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"User Query: '{user_message_content}'\\n\\nRelevant Info from Memory:\\n{retrieved_memories_text}\"\n",
    "            })\n",
    "\n",
    "            # 从 LLM 获取助手响应\n",
    "            assistant_response_text, p_tokens, c_tokens = get_llm_chat_completion(\n",
    "                messages_for_llm,\n",
    "                max_tokens=120,\n",
    "                verbose=VERBOSE_MEM0_RUN\n",
    "            )\n",
    "\n",
    "            # 更新全局令牌计数器\n",
    "            total_prompt_tokens_mem0_conversation += p_tokens\n",
    "            total_completion_tokens_mem0_conversation += c_tokens\n",
    "\n",
    "            print(f\"助手: {assistant_response_text[:80]}...\")\n",
    "            if VERBOSE_MEM0_RUN:\n",
    "                print(f\"  查询响应的令牌 (P: {p_tokens}, C: {c_tokens})\")\n",
    "\n",
    "            # 记录响应和令牌使用情况\n",
    "            turn_log_entry['assistant_response_conversational'] = assistant_response_text\n",
    "            turn_log_entry['prompt_tokens_conversational_turn'] = p_tokens\n",
    "            turn_log_entry['completion_tokens_conversational_turn'] = c_tokens\n",
    "\n",
    "        # 更新提取上下文日志（用于未来轮次的事实提取）\n",
    "        raw_conversation_log_for_extraction_context.append(f\"T{turn_index+1} U: {user_message_content}\")\n",
    "        raw_conversation_log_for_extraction_context.append(f\"T{turn_index+1} A: {assistant_response_text}\")\n",
    "\n",
    "        # 为 LLM 上下文更新短期聊天历史\n",
    "        current_short_term_llm_chat_history.extend([\n",
    "            {\"role\": \"user\", \"content\": user_message_content},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_response_text}\n",
    "        ])\n",
    "        # 截断聊天历史以仅保留最近的 N 轮（加上系统提示）\n",
    "        if len(current_short_term_llm_chat_history) > (1 + SHORT_TERM_CHAT_HISTORY_WINDOW * 2):\n",
    "            current_short_term_llm_chat_history = [current_short_term_llm_chat_history[0]] + \\\n",
    "                current_short_term_llm_chat_history[-(SHORT_TERM_CHAT_HISTORY_WINDOW*2):]\n",
    "\n",
    "        # 记录此轮次后的记忆存储大小\n",
    "        turn_log_entry['mem_store_size_after_turn'] = len(memory_store_instance.memories)\n",
    "        mem0_run_log.append(turn_log_entry)\n",
    "\n",
    "        if VERBOSE_MEM0_RUN:\n",
    "            print(f\"  当前 Mem0 存储大小: {len(memory_store_instance.memories)}\")\n",
    "\n",
    "        # 小延迟以避免 API 速率限制\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    print(\"\\n--- Mem0 驱动的对话方法摘要（全局计数器）---\")\n",
    "    # 如果需要，可以通过全局计数器获取最终令牌总数\n",
    "\n",
    "    if VERBOSE_MEM0_RUN:\n",
    "        print(\"\\n--- Mem0 记忆存储的最终内容 ---\")\n",
    "        if memory_store_instance.memories:\n",
    "            for mem_id, mem_item in memory_store_instance.memories.items():\n",
    "                print(f\"  ID: {mem_id}\\n    文本: '{mem_item.text}'\\n    创建: {mem_item.creation_timestamp.strftime('%H:%M:%S')}, 访问: {mem_item.access_count}, 最后: {mem_item.last_accessed_timestamp.strftime('%H:%M:%S')}, 来源: {mem_item.source_turn_indices}\")\n",
    "        else:\n",
    "            print(\"  Mem0 记忆存储为空。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2248c9",
   "metadata": {},
   "source": [
    "## 5. 执行和比较分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a61d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 比较分析的主要执行块 ---\n",
    "print(\"开始原始方法与 Mem0 方法的比较分析。\\n\")\n",
    "\n",
    "# --- 运行原始/全上下文方法 ---\n",
    "print(\"步骤 1: 运行原始/全上下文方法...\")\n",
    "\n",
    "# 重置所有全局令牌计数器和日志以确保干净的运行\n",
    "reset_all_token_counters_and_logs()\n",
    "\n",
    "# 设置原始方法的详细程度（设置为 True 获取详细日志）\n",
    "VERBOSE_RAW_RUN = False\n",
    "\n",
    "# 使用对话脚本运行原始/全上下文方法\n",
    "run_raw_full_context_approach(conversation_script)\n",
    "\n",
    "# 捕获原始方法的最终令牌计数\n",
    "final_raw_prompt_tokens = total_prompt_tokens_raw\n",
    "final_raw_completion_tokens = total_completion_tokens_raw\n",
    "final_raw_total_tokens = final_raw_prompt_tokens + final_raw_completion_tokens\n",
    "\n",
    "print(\"原始方法运行完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 运行 Mem0 驱动的方法 ---\n",
    "print(\"步骤 2: 运行 Mem0 驱动的对话方法...\")\n",
    "\n",
    "# 注意: 如果独立运行此单元格，请确保 Mem0 计数器和日志已重置以进行干净的运行。\n",
    "# 如果之前调用了 reset_all_token_counters_and_logs()，则计数器已被重置。\n",
    "# 如果只想运行 Mem0 部分，请取消注释下一行:\n",
    "# reset_all_token_counters_and_logs()\n",
    "\n",
    "# 清除之前的 Mem0 运行日志（如果有）（此处不重置 raw_run_log）\n",
    "global mem0_run_log\n",
    "mem0_run_log = []\n",
    "\n",
    "# 设置 Mem0 运行和记忆存储操作的详细程度\n",
    "VERBOSE_MEM0_RUN = False  # 设置为 True 获取详细的 Mem0 运行日志\n",
    "mem0_memory_store.verbose = VERBOSE_MEM0_RUN\n",
    "\n",
    "# 使用对话脚本运行 Mem0 驱动的对话方法\n",
    "run_mem0_approach_conversation(conversation_script, mem0_memory_store)\n",
    "\n",
    "# 收集每个子任务和整体的最终 Mem0 令牌计数\n",
    "final_mem0_conv_prompt_tokens = total_prompt_tokens_mem0_conversation\n",
    "final_mem0_conv_completion_tokens = total_completion_tokens_mem0_conversation\n",
    "final_mem0_extr_prompt_tokens = total_prompt_tokens_mem0_extraction\n",
    "final_mem0_extr_completion_tokens = total_completion_tokens_mem0_extraction\n",
    "final_mem0_upd_prompt_tokens = total_prompt_tokens_mem0_update\n",
    "final_mem0_upd_completion_tokens = total_completion_tokens_mem0_update\n",
    "\n",
    "# 计算 Mem0 总体提示、补全和总令牌数\n",
    "final_mem0_overall_prompt_tokens = (\n",
    "    final_mem0_conv_prompt_tokens + final_mem0_extr_prompt_tokens + final_mem0_upd_prompt_tokens\n",
    ")\n",
    "final_mem0_overall_completion_tokens = (\n",
    "    final_mem0_conv_completion_tokens + final_mem0_extr_completion_tokens + final_mem0_upd_completion_tokens\n",
    ")\n",
    "final_mem0_overall_total_tokens = (\n",
    "    final_mem0_overall_prompt_tokens + final_mem0_overall_completion_tokens\n",
    ")\n",
    "\n",
    "print(\"Mem0 方法运行完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为比较分析 DataFrame 准备数据字典\n",
    "# 每个键是一列: 'Metric', 'Raw Approach', 'Mem0 Approach'\n",
    "data = {\n",
    "    'Metric': [\n",
    "        'Prompt Tokens',                  # 使用的总提示令牌（原始 vs Mem0 总体）\n",
    "        'Completion Tokens',              # 使用的总补全令牌（原始 vs Mem0 总体）\n",
    "        'Total Tokens',                   # 总令牌（提示 + 补全）\n",
    "        '',                               # 为可读性分隔行\n",
    "        'Mem0: Conversational Prompt',    # Mem0: 对话（查询）轮次的提示令牌\n",
    "        'Mem0: Conversational Completion',# Mem0: 对话（查询）轮次的补全令牌\n",
    "        'Mem0: Extraction Prompt',        # Mem0: 提取子任务的提示令牌\n",
    "        'Mem0: Extraction Completion',    # Mem0: 提取子任务的补全令牌\n",
    "        'Mem0: Update Logic Prompt',      # Mem0: 更新逻辑子任务的提示令牌\n",
    "        'Mem0: Update Logic Completion'   # Mem0: 更新逻辑子任务的补全令牌\n",
    "    ],\n",
    "    'Raw Approach': [\n",
    "        final_raw_prompt_tokens,          # 原始方法: 总提示令牌\n",
    "        final_raw_completion_tokens,      # 原始方法: 总补全令牌\n",
    "        final_raw_total_tokens,           # 原始方法: 总令牌\n",
    "        '',                              # 分隔符（空白）\n",
    "        '-',                             # 原始方法不适用\n",
    "        '-',                             # 原始方法不适用\n",
    "        '-',                             # 原始方法不适用\n",
    "        '-',                             # 原始方法不适用\n",
    "        '-',                             # 原始方法不适用\n",
    "        '-'                              # 原始方法不适用\n",
    "    ],\n",
    "    'Mem0 Approach': [\n",
    "        final_mem0_overall_prompt_tokens,     # Mem0: 总体提示令牌（所有子任务之和）\n",
    "        final_mem0_overall_completion_tokens, # Mem0: 总体补全令牌（所有子任务之和）\n",
    "        final_mem0_overall_total_tokens,      # Mem0: 总体总令牌\n",
    "        '',                                   # 分隔符（空白）\n",
    "        final_mem0_conv_prompt_tokens,        # Mem0: 对话提示令牌\n",
    "        final_mem0_conv_completion_tokens,    # Mem0: 对话补全令牌\n",
    "        final_mem0_extr_prompt_tokens,        # Mem0: 提取提示令牌\n",
    "        final_mem0_extr_completion_tokens,    # Mem0: 提取补全令牌\n",
    "        final_mem0_upd_prompt_tokens,         # Mem0: 更新逻辑提示令牌\n",
    "        final_mem0_upd_completion_tokens      # Mem0: 更新逻辑补全令牌\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aed954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用准备好的数据字典创建比较分析的 DataFrame\n",
    "comparison_df = pd.DataFrame(data)\n",
    "\n",
    "# 基于令牌使用情况打印分析摘要\n",
    "print(\"\\n--- 分析 --- \")\n",
    "\n",
    "# 情况 1: 两种方法的令牌数均为零（可能是错误或不完整运行）\n",
    "if final_raw_total_tokens == 0 and final_mem0_overall_total_tokens == 0:\n",
    "    print(\"令牌计数均为零。确保运行成功完成并进行了 API 调用。\")\n",
    "\n",
    "# 情况 2: Mem0 方法使用的令牌比原始方法少（令牌节省）\n",
    "elif final_mem0_overall_total_tokens < final_raw_total_tokens:\n",
    "    savings = final_raw_total_tokens - final_mem0_overall_total_tokens\n",
    "    percentage_savings = (savings / final_raw_total_tokens) * 100 if final_raw_total_tokens > 0 else 0\n",
    "    print(f\"Mem0 更令牌高效，相比原始方法节省了 {savings} 个令牌（{percentage_savings:.2f}%）。\")\n",
    "\n",
    "# 情况 3: 原始方法使用的令牌比 Mem0 少（Mem0 的令牌开销）\n",
    "elif final_raw_total_tokens < final_mem0_overall_total_tokens:\n",
    "    overhead = final_mem0_overall_total_tokens - final_raw_total_tokens\n",
    "    percentage_overhead = (overhead / final_raw_total_tokens) * 100 if final_raw_total_tokens > 0 else float('inf')\n",
    "    print(f\"原始方法更令牌高效。Mem0 有 {overhead} 个令牌的开销（{percentage_overhead:.2f}%）。\")\n",
    "    print(\"（由于 Mem0 的提取/更新成本，这在短对话中是预期的。）\")\n",
    "\n",
    "# 情况 4: 两种方法使用大致相同的令牌数\n",
    "else:\n",
    "    print(f\"两种方法使用约 {final_mem0_overall_total_tokens} 个相同令牌。\")\n",
    "\n",
    "# 关于 Mem0 在长对话中优势的一般说明\n",
    "print(\"\\nMem0 的关键优势: 由于查询提示大小稳定，在*更长*对话中的令牌效率。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f498e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向比较 DataFrame 添加新列 'Percentage Difference'。\n",
    "# 对于每一行，如果 'Raw Approach' 和 'Mem0 Approach' 都是整数且 'Raw Approach' 不为零，\n",
    "# 计算百分比差异为:\n",
    "#   -((Mem0 Approach - Raw Approach) / Raw Approach) * 100\n",
    "# 这显示了令牌节省的百分比（正数表示 Mem0 使用更少令牌）。\n",
    "# 如果不适用，则设置为 None。\n",
    "comparison_df['Percentage Difference'] = comparison_df.apply(\n",
    "    lambda row: (\n",
    "        -(row['Mem0 Approach'] - row['Raw Approach']) / row['Raw Approach'] * 100\n",
    "        if isinstance(row['Raw Approach'], int) and isinstance(row['Mem0 Approach'], int) and row['Raw Approach'] != 0\n",
    "        else None\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ebfc44",
   "metadata": {},
   "source": [
    "## 6. 预期结果讨论和进一步改进\n",
    "\n",
    "在使用强大的 LLM 运行笔记本后：\n",
    "\n",
    "**令牌效率**:\n",
    "*   对于短对话，Mem0 的提取/更新开销可能使其总令牌数与原始方法相当或略高。然而，对于更长的对话，Mem0 应该变得显著更令牌高效，因为其查询提示大小（查询 + K 个检索的记忆）保持稳定，而原始方法的提示（完整历史）线性增长。\n",
    "\n",
    "**响应质量和上下文处理**:\n",
    "*   **原始方法**: 对于强大的 LLM 可能表现良好，但存在\"中间迷失\"问题、近因偏差以及在非常长的上下文中处理冲突/更新信息的困难。\n",
    "*   **Mem0 方法**: 旨在使用相关检索的记忆提供集中、准确的响应。`UPDATE` 机制是处理演变信息的关键。质量取决于准确的提取和更新逻辑。\n",
    "\n",
    "**本笔记本 Mem0 的挑战和改进**:\n",
    "*   **LLM 依赖性**: Mem0 的内部操作（提取、更新决策）高度依赖于 `LLM_MODEL` 的能力。\n",
    "*   **提示工程**: 提取和更新的提示至关重要，可以不断改进。\n",
    "*   **错误处理**: 更健壮的 LLM JSON 输出解析和错误恢复。\n",
    "*   **完整 Mem0 功能**: 实现 `DELETE`、对话摘要 `S` 和图记忆（`Mem0g`）将更接近论文。\n",
    "\n",
    "本笔记本作为基础探索。生产就绪的系统需要更多工程，并可能需要对记忆子任务进行微调模型。"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
